{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv shape is  (750000, 12)\n",
      "test.csv shape is  (250000, 11)\n",
      "\n",
      "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre   \n",
      "0   0  Mystery Matters    Episode 98                     NaN  True Crime  \\\n",
      "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
      "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
      "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
      "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
      "\n",
      "   Host_Popularity_percentage Publication_Day Publication_Time   \n",
      "0                       74.81        Thursday            Night  \\\n",
      "1                       66.95        Saturday        Afternoon   \n",
      "2                       69.97         Tuesday          Evening   \n",
      "3                       57.22          Monday          Morning   \n",
      "4                       80.07          Monday        Afternoon   \n",
      "\n",
      "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment   \n",
      "0                          NaN            0.0          Positive  \\\n",
      "1                        75.95            2.0          Negative   \n",
      "2                         8.97            0.0          Negative   \n",
      "3                        78.70            2.0          Positive   \n",
      "4                        58.68            3.0           Neutral   \n",
      "\n",
      "   Listening_Time_minutes  \n",
      "0                31.41998  \n",
      "1                88.01241  \n",
      "2                44.92531  \n",
      "3                46.27824  \n",
      "4                75.61031  \n",
      "\n",
      "       id         Podcast_Name Episode_Title  Episode_Length_minutes   \n",
      "0  750000  Educational Nuggets    Episode 73                   78.96  \\\n",
      "1  750001          Sound Waves    Episode 23                   27.87   \n",
      "2  750002        Joke Junction    Episode 11                   69.10   \n",
      "3  750003        Comedy Corner    Episode 73                  115.39   \n",
      "4  750004         Life Lessons    Episode 50                   72.32   \n",
      "\n",
      "       Genre  Host_Popularity_percentage Publication_Day Publication_Time   \n",
      "0  Education                       38.11        Saturday          Evening  \\\n",
      "1      Music                       71.29          Sunday          Morning   \n",
      "2     Comedy                       67.89          Friday          Evening   \n",
      "3     Comedy                       23.40          Sunday          Morning   \n",
      "4  Lifestyle                       58.10       Wednesday          Morning   \n",
      "\n",
      "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \n",
      "0                        53.33            1.0           Neutral  \n",
      "1                          NaN            0.0           Neutral  \n",
      "2                        97.51            0.0          Positive  \n",
      "3                        51.75            2.0          Positive  \n",
      "4                        11.30            2.0           Neutral  \n",
      "\n",
      "                  id  Episode_Length_minutes  Host_Popularity_percentage   \n",
      "count  750000.000000           662907.000000               750000.000000  \\\n",
      "mean   374999.500000               64.504738                   59.859901   \n",
      "std    216506.495284               32.969603                   22.873098   \n",
      "min         0.000000                0.000000                    1.300000   \n",
      "25%    187499.750000               35.730000                   39.410000   \n",
      "50%    374999.500000               63.840000                   60.050000   \n",
      "75%    562499.250000               94.070000                   79.530000   \n",
      "max    749999.000000              325.240000                  119.460000   \n",
      "\n",
      "       Guest_Popularity_percentage  Number_of_Ads  Listening_Time_minutes  \n",
      "count                603970.000000  749999.000000           750000.000000  \n",
      "mean                     52.236449       1.348855               45.437406  \n",
      "std                      28.451241       1.151130               27.138306  \n",
      "min                       0.000000       0.000000                0.000000  \n",
      "25%                      28.380000       0.000000               23.178350  \n",
      "50%                      53.580000       1.000000               43.379460  \n",
      "75%                      76.600000       2.000000               64.811580  \n",
      "max                     119.910000     103.910000              119.970000  \n"
     ]
    }
   ],
   "source": [
    "trainingSet = pd.read_csv('./data/train.csv')\n",
    "testingSet = pd.read_csv('./data/test.csv')\n",
    "\n",
    "\n",
    "print(\"train.csv shape is \", trainingSet.shape)\n",
    "print(\"test.csv shape is \", testingSet.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(trainingSet.head())\n",
    "print()\n",
    "print(testingSet.head())\n",
    "\n",
    "print()\n",
    "\n",
    "print(trainingSet.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = trainingSet.sample(frac=0.4, random_state=1)\n",
    "# save to csv\n",
    "trainingSet.to_csv('./data/train_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Remove the columns that are not useful for training\n",
    "train_data = trainingSet.drop(columns=['id', 'Podcast_Name', 'Episode_Title'])\n",
    "test_data = testingSet.drop(columns=['id', 'Podcast_Name','Episode_Title'])\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
    "continuous_columns = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage']\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_columns)\n",
    "test_data = pd.get_dummies(test_data, columns=categorical_columns)\n",
    "\n",
    "# Drop missing values\n",
    "train_data = train_data.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = train_data.drop(columns=['Listening_Time_minutes'])\n",
    "y = train_data['Listening_Time_minutes']\n",
    "\n",
    "# normalize only the continuous features, not all\n",
    "scaler = StandardScaler()\n",
    "X[continuous_columns] = scaler.fit_transform(X[continuous_columns])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 431238, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 45.829445\n",
      "Train RMSE: 10.17\n",
      "Validation RMSE: 10.38\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "params = {\n",
    "    \"reg_alpha\": 0.006873126119178912,\n",
    "    \"reg_lambda\": 0.145379437299848,\n",
    "    \"num_leaves\": 85,\n",
    "    \"max_bin\": 2**8,  \n",
    "    \"n_estimators\": 483,\n",
    "    \"learning_rate\": 0.034522923546535,\n",
    "    \"colsample_bytree\": 0.5935293824087292,\n",
    "    \"min_child_samples\": 5,\n",
    "    \"random_state\": 42  \n",
    "}\n",
    "\n",
    "model = LGBMRegressor(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, model.predict(X_train), squared=False)\n",
    "val_rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse:.2f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "X_test = test_data\n",
    "# fill missing values\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "X_test[continuous_columns] = scaler.transform(X_test[continuous_columns])\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Save the predictions to CSV \n",
    "submission = pd.DataFrame({'id': testingSet['id'], 'Listening_Time_minutes': y_test_pred})\n",
    "submission.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
